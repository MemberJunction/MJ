import { AIErrorInfo } from './errorTypes.js';

export class BaseResult {
    success: boolean
    startTime: Date
    endTime: Date
    errorMessage: string
    exception: any
    /**
     * Structured error information for better error handling and retry logic
     */
    errorInfo?: AIErrorInfo
    get timeElapsed(): number {
        return this.endTime.getTime() - this.startTime.getTime();
    }
    constructor (success: boolean, startTime: Date, endTime: Date) {
        this.success = success;
        this.startTime = startTime;
        this.endTime = endTime;
    }
}

export class BaseParams {
    /**
     * Model name, required.
     */
    model: string
    
    /**
     * Model temperature, optional.
     */
    temperature?: number

    /**
     * Specifies the format that the model should output. Not all models support all formats. If not specified, the default is 'Any'.
     */
    responseFormat?: 'Any' | 'Text' | 'Markdown' | 'JSON' | 'ModelSpecific' = 'Any';

    /**
     * The standard response formats may not be sufficient for all models. This field allows for a model-specific response format to be specified. For this field to be used, responseFormat must be set to 'ModelSpecific'. 
     */
    modelSpecificResponseFormat?: any

    /**
     * Model max output response tokens, optional.
     */
    maxOutputTokens?: number

    /**
     * Model max budget tokens that we may use for reasoning in reasoning models, optional.
     */
    reasoningBudgetTokens?: number

    /**
     * Optional seed for reproducible outputs.
     * Not all models support seeding, but when supported, using the same seed
     * with the same inputs should produce identical outputs.
     */
    seed?: number

    /**
     * Optional array of sequences where the model will stop generating further tokens.
     * The returned text will not contain the stop sequence.
     */
    stopSequences?: string[]
}

/**
 * Represents token usage and cost information for an AI model execution.
 * 
 * This class tracks the number of tokens used in both the prompt (input) and
 * completion (output) phases of an AI model execution, along with optional
 * cost information when provided by the AI provider.
 * 
 * @class ModelUsage
 * @since 2.43.0
 */
export class ModelUsage {
    /**
     * Creates a new ModelUsage instance.
     * 
     * @param {number} promptTokens - Number of tokens used in the prompt/input
     * @param {number} completionTokens - Number of tokens generated in the completion/output
     * @param {number} [cost] - Optional cost of the execution
     * @param {string} [costCurrency] - Optional currency code for the cost (e.g., 'USD', 'EUR', 'GBP')
     */
    constructor(promptTokens: number, completionTokens: number, cost?: number, costCurrency?: string) {
        this.promptTokens = promptTokens;
        this.completionTokens = completionTokens;
        if (cost !== undefined) {
            this.cost = cost;
        }
        if (costCurrency !== undefined) {
            this.costCurrency = costCurrency;
        }
    }
    
    /**
     * Number of tokens used in the prompt/input phase.
     * This includes all tokens from system messages, user messages, and any
     * other context provided to the model.
     */
    promptTokens: number
    
    /**
     * Number of tokens generated by the model in its response.
     * This represents the length of the model's output.
     */
    completionTokens: number
    
    /**
     * Optional cost of this execution.
     * The currency is specified in the costCurrency field.
     * Some providers (like Anthropic) provide this information directly in their API responses.
     */
    cost?: number
    
    /**
     * Optional ISO 4217 currency code for the cost field.
     * Examples: 'USD', 'EUR', 'GBP', 'JPY', etc.
     * If not specified when cost is provided, the currency is provider-specific.
     */
    costCurrency?: string
    
    /**
     * Optional queue time in milliseconds before the model started processing the request.
     * This is a provider-specific timing metric that may not be available from all providers.
     */
    queueTime?: number
    
    /**
     * Optional time in milliseconds for the model to ingest and process the prompt.
     * This is a provider-specific timing metric that may not be available from all providers.
     */
    promptTime?: number
    
    /**
     * Optional time in milliseconds for the model to generate the completion/response tokens.
     * This is a provider-specific timing metric that may not be available from all providers.
     */
    completionTime?: number
    
    /**
     * Calculated total number of tokens (prompt + completion).
     * This is useful for tracking overall token usage against limits.
     * 
     * @returns {number} The sum of promptTokens and completionTokens
     */
    get totalTokens(): number {
        return this.promptTokens + this.completionTokens;
    }
}

/**
 * Base AI model class, used for everything else in the MemberJunction AI environment
 */
export abstract class BaseModel {
    private _apiKey: string;
    /**
     * Only sub-classes can access the API key
     */
    protected get apiKey(): string {
        return this._apiKey;
    }
    constructor (apiKey: string) {
        if (!apiKey || apiKey.trim().length === 0)
            console.warn('BaseModel: API key is empty, this might cause issues with model execution');

        this._apiKey = apiKey;
    }
}
